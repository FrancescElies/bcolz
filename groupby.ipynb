{
 "metadata": {
  "name": "",
  "signature": "sha256:048f4bee8b60f82b76916c3ab7cae11632014cb1c0c34e24f33b54b49cb19f64"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Groupby tests"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Create data frame\n",
      "import bcolz\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import tempfile\n",
      "import os\n",
      "import cython\n",
      "import shutil\n",
      "from prettyprint import pp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext cythonmagic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Option 1) groupby"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def groupby_opt_1(self, groupby_cols, measure_cols):\n",
      "    \"\"\"\n",
      "    Groups the measure_cols over the groupby_cols. Currently only sums are supported.\n",
      "    NB: current Python standard hash *might* have collisions!\n",
      "\n",
      "    :param groupby_cols: A list of groupby columns\n",
      "    :param measure_cols: A list of measure columns (sum only atm)\n",
      "    :return:\n",
      "    \"\"\"\n",
      "\n",
      "    arr_len = self.size\n",
      "    # Make a new integer carry index_arr with the length of the ctable\n",
      "    # -> this will have a per-row index where the new value will go\n",
      "    index_arr = bcolz.carray(np.zeros(arr_len, dtype=int))\n",
      "    # Make a new type x carry hash_arr with the length of the ctable\n",
      "    # -> this will have a hash code of the group by columns;\n",
      "    hash_arr = bcolz.carray(np.zeros(arr_len, dtype=int))\n",
      "    # Make an integer variable hash_max that starts at 0\n",
      "    hash_max = 0\n",
      "    previous_hash = 0\n",
      "    current_index = 0\n",
      "\n",
      "    # first create an overview of which row goes where (fill the index array)\n",
      "    i = 0\n",
      "    for row in self.iter(outcols=groupby_cols):\n",
      "        current_hash = hash(row)\n",
      "        # if the current_hash is unlike the previous hash, lookup the new index value\n",
      "        if current_hash != previous_hash:\n",
      "            # check if it already exists as a known value\n",
      "            hash_found = False\n",
      "            for j in range(hash_max):\n",
      "                if current_hash == hash_arr[j]:\n",
      "                    current_index = j\n",
      "                    hash_found = True\n",
      "                    break\n",
      "            # if it does not exist yet, add it to the hash_arr\n",
      "            if not hash_found:\n",
      "                current_index = hash_max\n",
      "                hash_arr[current_index] = current_hash\n",
      "                hash_max += 1\n",
      "        # save where the current row has to go\n",
      "        index_arr[i] = current_index\n",
      "        # get ready for the next row of the loop\n",
      "        previous_hash = current_hash\n",
      "        i += 1\n",
      "\n",
      "    # now create the output data frame\n",
      "    outcols = groupby_cols + measure_cols\n",
      "    new_matrix = [np.zeros(hash_max, self.dtype[col]) for col in outcols]\n",
      "    output_table = bcolz.ctable(columns=new_matrix, names=outcols)\n",
      "\n",
      "    # and write away the new values by using the index array\n",
      "    i = 0\n",
      "    groupby_cols_set = set(groupby_cols)\n",
      "    measure_cols_set = set(measure_cols)\n",
      "    for row in self.iter(outcols=outcols):\n",
      "        current_index = index_arr[i]\n",
      "        # save groupby cols\n",
      "        # (a bit unefficient because it does not have to do that each time normally, but only the first time)\n",
      "        for col in groupby_cols_set:\n",
      "            output_table[col][current_index] = row.__getattribute__(col)\n",
      "        # do sum operation (only sum atm; have to add mean, median, min, max, etc. in future)\n",
      "        for col in measure_cols_set:\n",
      "            output_table[col][current_index] += row.__getattribute__(col)\n",
      "        # get ready for the next row of the loop\n",
      "        i += 1\n",
      "\n",
      "    return output_table"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Option 2) groupby"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%cython\n",
      "import numpy as np\n",
      "cimport numpy as np\n",
      "import cython\n",
      "import bcolz\n",
      "@cython.boundscheck(False)\n",
      "@cython.wraparound(False)\n",
      "cpdef groupby_opt_2_cython(input_gen, list groupby_cols, list measure_cols):\n",
      "    \"\"\"\n",
      "    Groups the measure_cols over the groupby_cols. Currently only sums are supported.\n",
      "    NB: current Python standard hash *might* have collisions!\n",
      "\n",
      "    :param groupby_cols: A list of groupby columns\n",
      "    :param measure_cols: A list of measure columns (sum only atm)\n",
      "    :return:\n",
      "    \"\"\"\n",
      "    cdef int arr_len, i, j, col_nr, hash_max, current_hash, previous_hash, current_index\n",
      "    cdef str col\n",
      "    # cdef tuple row <- namedtuple issue?\n",
      "    cdef list outcols\n",
      "    # cdef bcolz.carray_ext.carray index_arr, hash_arr, current_col <- array issue\n",
      "    arr_len = input_gen.size\n",
      "    # Make a new integer carry index_arr with the length of the ctable\n",
      "    # -> this will have a per-row index where the new value will go\n",
      "    index_arr = bcolz.carray(np.zeros(arr_len, dtype=int))\n",
      "    # Make a new type x carry hash_arr with the length of the ctable\n",
      "    # -> this will have a hash code of the group by columns;\n",
      "    hash_arr = bcolz.carray(np.zeros(arr_len, dtype=int))\n",
      "    # Make an integer variable hash_max that starts at 0\n",
      "    hash_max = 0\n",
      "    previous_hash = 0\n",
      "    current_index = 0\n",
      "    # first create an overview of which row goes where (fill the index array)\n",
      "    i = 0\n",
      "    for row in input_gen.iter(outcols=groupby_cols):\n",
      "        current_hash = hash(row)\n",
      "        # if the current_hash is unlike the previous hash, lookup the new index value\n",
      "        if current_hash != previous_hash:\n",
      "            # check if it already exists as a known value\n",
      "            hash_found = False\n",
      "            for j in range(hash_max):\n",
      "                if current_hash == hash_arr[j]:\n",
      "                    current_index = j\n",
      "                    hash_found = True\n",
      "                    break\n",
      "            # if it does not exist yet, add it to the hash_arr\n",
      "            if not hash_found:\n",
      "                current_index = hash_max\n",
      "                hash_arr[current_index] = current_hash\n",
      "                hash_max += 1\n",
      "        # save where the current row has to go\n",
      "        index_arr[i] = current_index\n",
      "        # get ready for the next row of the loop\n",
      "        previous_hash = current_hash\n",
      "        i += 1\n",
      "    # now create the output data frame\n",
      "    outcols = groupby_cols + measure_cols\n",
      "    new_matrix = [np.zeros(hash_max, input_gen.dtype[col]) for col in outcols]\n",
      "    output_table = bcolz.ctable(columns=new_matrix, names=outcols)\n",
      "    # and write away the new values by using the index array\n",
      "    i = 0\n",
      "    for row in input_gen.iter(outcols=outcols):\n",
      "        current_index = index_arr[i]\n",
      "        # save groupby cols\n",
      "        # (a bit unefficient because it does not have to do that each time normally, but only the first time)\n",
      "        col_nr = 0\n",
      "        for col in groupby_cols:\n",
      "            current_col = output_table.cols[col]\n",
      "            current_col[current_index] = row[col_nr]\n",
      "            col_nr += 1\n",
      "        # do sum operation (only sum atm; have to add mean, median, min, max, etc. in future)\n",
      "        for col in measure_cols:\n",
      "            current_col = output_table.cols[col]\n",
      "            current_col[current_index] += row[col_nr]\n",
      "            col_nr += 1\n",
      "        # get ready for the next row of the loop\n",
      "        i += 1\n",
      "    return output_table\n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Option 3) groupby"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def _hash_dict_opt_3(self, group_id):\n",
      "    if isinstance(group_id.values()[0], dict):\n",
      "        return hash(frozenset(group_id.keys()[0])) + \\\n",
      "               hash(frozenset(group_id.values()[0]))\n",
      "    else:\n",
      "        return hash(frozenset(group_id.items()))\n",
      "\n",
      "def _groupby_sum_opt_3(self, *args):\n",
      "    sum = 0.0\n",
      "    for item in args:\n",
      "        sum += item\n",
      "    return sum\n",
      "\n",
      "def _calc_aggs_opt_3(self, aggs, agg_field_name, group_id, group_hash_id, inv_aggs_hash_ids, row):\n",
      "    # agg_name = group_hash_id\n",
      "    func_and_paras = agg_field_name.values()[0]\n",
      "    function = func_and_paras.keys()[0]\n",
      "    in_fields = func_and_paras.values()[0]\n",
      "    agg_hash_id = _hash_dict_opt_3(self, agg_field_name) + group_hash_id\n",
      "    inv_aggs_hash_ids[agg_hash_id] = agg_field_name, group_id\n",
      "    if function == 'sum':\n",
      "        f = _groupby_sum_opt_3\n",
      "    else:\n",
      "        raise ValueError(\n",
      "            u'Aggregation {0:s} not available'.format(function)\n",
      "        )\n",
      "\n",
      "    dependency_fields = []\n",
      "    for field in in_fields:\n",
      "        pos = self.names.index(field)\n",
      "        dependency_fields.append(row[pos])\n",
      "    aggs[agg_hash_id] += f(self, *dependency_fields)\n",
      "\n",
      "def groupby_opt_3(self, cols, agg_fields):\n",
      "    import glob\n",
      "    import tempfile\n",
      "    from collections import defaultdict\n",
      "\n",
      "    assert isinstance(cols, list)\n",
      "    assert cols != []\n",
      "    assert isinstance(agg_fields, list)\n",
      "    assert agg_fields != {}\n",
      "\n",
      "    index_groups = defaultdict(dict)\n",
      "    aggs = defaultdict(float)\n",
      "    inv_aggs_hash_ids = {}\n",
      "\n",
      "    # # Check input\n",
      "    for agg_field in agg_fields:\n",
      "        assert agg_field not in cols\n",
      "    for col in cols:\n",
      "        assert col in self.names\n",
      "\n",
      "\n",
      "    prefix = 'bcolz_groupby_'\n",
      "    for row in self:\n",
      "        group_id = {}\n",
      "\n",
      "        for col in cols:\n",
      "            pos = self.names.index(col)\n",
      "            group_id[col] = row[pos]\n",
      "\n",
      "        group_hash_id = _hash_dict_opt_3(self, group_id)\n",
      "\n",
      "        if group_hash_id not in index_groups:\n",
      "            rootdir = tempfile.mkdtemp(prefix=prefix)\n",
      "            os.rmdir(rootdir)  # groupby needs this cleared\n",
      "            t = bcolz.ctable(\n",
      "                columns=[[x] for x in row],\n",
      "                names=self.cols.names,\n",
      "                rootdir=rootdir\n",
      "            )\n",
      "\n",
      "            # index the the new created ctable for future use\n",
      "            index_groups[group_hash_id] = \\\n",
      "                {\n",
      "                    'group_id': group_id,\n",
      "                    'ctable': t\n",
      "                }\n",
      "            # update calculated aggregations\n",
      "            for agg_field_name in agg_fields:\n",
      "                _calc_aggs_opt_3(self, aggs, agg_field_name, group_id, group_hash_id, inv_aggs_hash_ids, row)\n",
      "        else:\n",
      "            t = index_groups[group_hash_id]['ctable']\n",
      "            t.append([[x] for x in row])\n",
      "\n",
      "            # update calculated aggregations\n",
      "            for agg_field_name in agg_fields:\n",
      "                _calc_aggs_opt_3(self, aggs, agg_field_name, group_id, group_hash_id, inv_aggs_hash_ids, row)\n",
      "\n",
      "            # -- print grouped by --\n",
      "            # for key in index_groups:\n",
      "            #     for row in index_groups[key]['ctable']:\n",
      "            #         print row\n",
      "            #     pp(index_groups[key]['group_id'])\n",
      "\n",
      "    # remove temporary folders\n",
      "    for idexed_group in index_groups.values():\n",
      "        t = idexed_group['ctable']\n",
      "        for dir_ in glob.glob(t.rootdir+'*'):\n",
      "            shutil.rmtree(dir_)\n",
      "\n",
      "    # Transform output to pandas\n",
      "    return aggs, inv_aggs_hash_ids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Option 4) groupby cython opt.3"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%cython\n",
      "import numpy as np\n",
      "cimport numpy as np\n",
      "import cython\n",
      "import bcolz\n",
      "import os\n",
      "import cython\n",
      "import shutil\n",
      "import glob\n",
      "import tempfile\n",
      "from collections import defaultdict\n",
      "\n",
      "cpdef _hash_dict_opt_4(self, group_id):\n",
      "    if isinstance(group_id.values()[0], dict):\n",
      "        return hash(frozenset(group_id.keys()[0])) + \\\n",
      "               hash(frozenset(group_id.values()[0]))\n",
      "    else:\n",
      "        return hash(frozenset(group_id.items()))\n",
      "\n",
      "cpdef _groupby_sum_opt_4(self, list args):\n",
      "    sum = 0.0\n",
      "    for item in args:\n",
      "        sum += item\n",
      "    return sum\n",
      "\n",
      "def _calc_aggs_opt_4(self, aggs, dict agg_field_name, group_id, group_hash_id, inv_aggs_hash_ids, row):\n",
      "    # agg_name = group_hash_id\n",
      "    func_and_paras = agg_field_name.values()[0]\n",
      "    function = func_and_paras.keys()[0]\n",
      "    in_fields = func_and_paras.values()[0]\n",
      "    agg_hash_id = _hash_dict_opt_4(self, agg_field_name) + group_hash_id\n",
      "    inv_aggs_hash_ids[agg_hash_id] = agg_field_name, group_id\n",
      "    if function == 'sum':\n",
      "        f = _groupby_sum_opt_4\n",
      "    else:\n",
      "        raise ValueError(\n",
      "            u'Aggregation {0:s} not available'.format(function)\n",
      "        )\n",
      "\n",
      "    dependency_fields = []\n",
      "    for field in in_fields:\n",
      "        pos = self.names.index(field)\n",
      "        dependency_fields.append(row[pos])\n",
      "    if agg_hash_id in aggs:\n",
      "        aggs[agg_hash_id] += f(self, dependency_fields)\n",
      "    else:\n",
      "        aggs[agg_hash_id] = f(self, dependency_fields)\n",
      "        \n",
      "\n",
      "cpdef groupby_opt_4(self, list cols, list agg_fields):\n",
      "    cdef str col\n",
      "    cdef dict agg_field_name, inv_aggs_hash_ids, group_id, aggs\n",
      "    cdef long group_hash_id\n",
      "    \n",
      "    assert isinstance(cols, list)\n",
      "    assert cols != []\n",
      "    assert isinstance(agg_fields, list)\n",
      "    assert agg_fields != {}\n",
      "\n",
      "    index_groups = defaultdict(dict)\n",
      "    aggs = {}\n",
      "    inv_aggs_hash_ids = {}\n",
      "\n",
      "    # # Check input\n",
      "    for agg_field in agg_fields:\n",
      "        assert agg_field not in cols\n",
      "    for col in cols:\n",
      "        assert col in self.names\n",
      "\n",
      "\n",
      "    prefix = 'bcolz_groupby_'\n",
      "    for row in self:\n",
      "        group_id = {}\n",
      "\n",
      "        for col in cols:\n",
      "            pos = self.names.index(col)\n",
      "            group_id[col] = row[pos]\n",
      "\n",
      "        group_hash_id = _hash_dict_opt_4(self, group_id)\n",
      "\n",
      "        if group_hash_id not in index_groups:\n",
      "            rootdir = tempfile.mkdtemp(prefix=prefix)\n",
      "            os.rmdir(rootdir)  # groupby needs this cleared\n",
      "            t = bcolz.ctable(\n",
      "                columns=[[x] for x in row],\n",
      "                names=self.cols.names,\n",
      "                rootdir=rootdir\n",
      "            )\n",
      "\n",
      "            # index the the new created ctable for future use\n",
      "            index_groups[group_hash_id] = \\\n",
      "                {\n",
      "                    'group_id': group_id,\n",
      "                    'ctable': t\n",
      "                }\n",
      "            # update calculated aggregations\n",
      "            for agg_field_name in agg_fields:\n",
      "                _calc_aggs_opt_4(self, aggs, agg_field_name, group_id, group_hash_id, inv_aggs_hash_ids, row)\n",
      "        else:\n",
      "            t = index_groups[group_hash_id]['ctable']\n",
      "            t.append([[x] for x in row])\n",
      "\n",
      "            # update calculated aggregations\n",
      "            for agg_field_name in agg_fields:\n",
      "                _calc_aggs_opt_4(self, aggs, agg_field_name, group_id, group_hash_id, inv_aggs_hash_ids, row)\n",
      "\n",
      "            # -- print grouped by --\n",
      "            # for key in index_groups:\n",
      "            #     for row in index_groups[key]['ctable']:\n",
      "            #         print row\n",
      "            #     pp(index_groups[key]['group_id'])\n",
      "\n",
      "    # remove temporary folders\n",
      "    for idexed_group in index_groups.values():\n",
      "        t = idexed_group['ctable']\n",
      "        for dir_ in glob.glob(t.rootdir+'*'):\n",
      "            shutil.rmtree(dir_)\n",
      "\n",
      "    # Transform output to pandas\n",
      "    return aggs, inv_aggs_hash_ids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Timeit different solutions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## load testing data set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "projects = [\n",
      "    {'name': 'build roads',  'state': 'CA', 'cost':   1, 'cost2':  2, 'cost3':    3},\n",
      "    {'name': 'fight crime',  'state': 'IL', 'cost':   2, 'cost2':  3, 'cost3':    4},\n",
      "    {'name': 'help farmers', 'state': 'IL', 'cost':   4, 'cost2':  5, 'cost3':    6},\n",
      "    {'name': 'help farmers', 'state': 'CA', 'cost':   8, 'cost2':  9, 'cost3':   10},\n",
      "    {'name': 'build roads',  'state': 'CA', 'cost':  16, 'cost2': 17, 'cost3':   18},\n",
      "    {'name': 'fight crime',  'state': 'IL', 'cost':  32, 'cost2': 33, 'cost3':   34},\n",
      "    {'name': 'help farmers', 'state': 'IL', 'cost':  64, 'cost2': 65, 'cost3':   66},\n",
      "    {'name': 'help farmers', 'state': 'AR', 'cost': 128, 'cost2': 129, 'cost3': 130}\n",
      "]\n",
      "\n",
      "df_tmp = pd.DataFrame(projects)\n",
      "df = [df_tmp for i in range(10000)]\n",
      "df = pd.concat(df, ignore_index=True)\n",
      "\n",
      "prefix = 'bcolz-TestH5'\n",
      "rootdir = tempfile.mkdtemp(prefix=prefix)\n",
      "os.rmdir(rootdir)  # raise exception if folder not empty\n",
      "\n",
      "fact_bcolz = bcolz.ctable.fromdataframe(df, rootdir=rootdir, mode='w')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Timeit"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### groupby 0) pandas reference"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print df.groupby(['state','name'])['cost', 'cost3'].sum()\n",
      "%timeit df.groupby(['state','name'])['cost', 'cost3'].sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### groupby 1)"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "pp(groupby_opt_1(fact_bcolz ,      ['state'], ['cost', 'cost3']))\n",
      "%timeit groupby_opt_1(fact_bcolz , ['state'], ['cost', 'cost3'])"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### groupby 2)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# pp(groupby_opt_2_cython(fact_bcolz ,      ['state','name'], ['cost', 'cost3']))\n",
      "%timeit groupby_opt_2_cython(fact_bcolz , ['state','name'], ['cost', 'cost3'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### groupby 3)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# pp(groupby_opt_3(fact_bcolz,      ['state','name'], [{'sum_costs':{'sum': ['cost']}}, {'sum_costs3':{'sum': ['cost3']}}]))\n",
      "%timeit groupby_opt_3(fact_bcolz, ['state','name'], [{'sum_costs':{'sum': ['cost']}}, {'sum_costs3':{'sum': ['cost3']}}])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### groupby 4)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# pp(groupby_opt_4(fact_bcolz,      ['state','name'], [{'sum_costs':{'sum': ['cost']}}, {'sum_costs3':{'sum': ['cost3']}}]))\n",
      "%timeit groupby_opt_4(fact_bcolz, ['state','name'], [{'sum_costs':{'sum': ['cost']}}, {'sum_costs3':{'sum': ['cost3']}}])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### group 3) other type of aggregations"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# pp(groupby_opt_3(fact_bcolz,      ['state','name'], [{'sum_costs':{'sum': ['cost', 'cost3']}}]))\n",
      "%timeit groupby_opt_3(fact_bcolz, ['state','name'], [{'sum_costs':{'sum': ['cost', 'cost3']}}])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}